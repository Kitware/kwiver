KWIVER v1.1.0 Release Notes
===========================

This is a minor release of KWIVER that provides both new functionality and
fixes over the previous v1.0.0 release.  There are numerous changes in this
release that have been motivated primarily by three different applications
of KWIVER.  One is the use of KWIVER in MAP-Tk to provide 3D reconstruction
algorithms to the MAP-Tk tools and TeleSculptor GUI application.  This
work has been largely sponsored by the US Air Force Research Laboratories.
A second driving factor is the use of KWIVER as an evaluation framework for
video surveillance applications in the upcoming IARPA DIVA program.  The
third driving factor for improvements in this release is the use of KWIVER
as the basis for the VIAME toolkit for underwater image processing, supported
by NOAA.  These project needs have improved the general processing framework
of KWIVER as well as specific algorithm improvements in 3D reconstruction
and object detection in video.

Vital, the core framework of KWIVER, has been updated in several ways in
this release.  Previously there were multiple plugin loader mechanisms
stemming from the origins of KWIVER as the fusion of multiple projects.
In this release there is now a unified plugin loader framework that provides
a common mechanism for loading algorithm plugins (Arrows), process and cluster
plugins (Sprokit), loggers (Vital), and so on.  There is also a single tool,
plugin_explorer, that allows introspection of these plugins of various types.
This release also has a new multi-threading API in Vital that provides an
interface for a thread pool with multiple back ends.  The thread pool API
allows KWIVER algorithms to more easily leverage parallel processing without
being tied to a single thread management library.  Additional back ends,
like Intel TBB, will be added in future releases.  C and Python bindings for
Vital have also been extended considerably in this release.

Some other changes in Vital enhance the way image data is loaded and stored.
This release generalizes the image data structure to support images with
various pixel types.  Previously Vital only supported 8-bit images.  It now
supports many pixel types including 16 and 32 bit integers and single and
double precision floating point types.  Also new in this release is a
video input API for reading image sequences directly from video sources.
There are implementations of this API in Arrows for reading video files
directly as well as lists of images.  The video API also supports reading
video metadata that is encoded with the video.

In support of the MAP-Tk TeleSculptor application, many abstract algorithms
in Vital and their implementations in Arrows now support callbacks.  These
callbacks allow the algorithms to report intermediate results or to signal the
algorithm to terminate early.  These callback are used in GUI applications
to get live updates of processing results and to allow users to cancel
processing.  This release also adds binary serialization for feature detectors
and descriptors, which allows algorithms to cache features and descriptors
on disk and load them back in later.  The algorithms for matching features
have also been improved for better handling of very large images.  Large images
are best matched by comparing features at a coarse scale before matching fine
scale features.

In support of the DIVA program, the Sprokit pipeline framework now supports
frame dropping and processing time-outs.  These changes help prevent the
pipeline from falling behind in applications that need to keep up with real
team processing requirements.  A pipeline can be configured to drop frames
if needed to catch up.

In support of the VIAME toolkit, this release adds new object detection
APIs and provides and implementation of those APIs use the Darknet YOLO
(You Only Look Once) network architecture.

There are many other smaller changes in this release.  These are detailed in
the change log below.



Updates since v1.0.0
--------------------

Arrows

 * Updated all algorithms to use the new plugin loader approach.

Arrows - Ceres

 * Added a Ceres implementation of the optimize_cameras abstract algorithm.
   This implementation is very similar to the bundle_adjust algorithm but
   does not modify the landmarks.

 * Refactored common config options and helper functions between
   optimize_cameras and bundle_adjust into new shared classes in options.h.
   This makes it much easer to create a new Ceres solver algorithm and
   reuse the same solver options or camera options.

 * Implemented callbacks for the Ceres bundle_adjust to emit the state of
   the optimization after each iteration if a callback is registered.

 * Added two forms of camera path regularization to the bundle_adjust and
   optimize_cameras algorithms.  The first adds a cost that favors smooth
   camera paths; the camera location at time t should be close to the
   average of locations at t-1 and t+1.  The second adds cost for cameras
   moving along the principal ray direction; this allows optimization to
   favor focal length change (zoom) over forward motion.

Arrows - Core

 * Added an option to the PCA canonical transform estimator to shift the ground
   plane vertically to place a configurable percentile of the landmarks above
   the ground.

 * Implemented callbacks for the core initialize_cameras_landmarks algorithm
   to emit the set of cameras and landmarks after each camera is added if a
   callback is registered.

 * Added logic to compute changes in ground sample distance (GSD) as images are
   added in the camera_landmark_initialization algorithm.  If GSD changes are
   above a threshold then assume the camera intrinsics have changed and create
   a new shared intrinsic model.  This allows for shared intrinsics when the
   camera does not zoom but varying intrinsics when zoom is detected.

 * Changed the order of when Necker reversal correction is attempted in the
   initialize_cameras_landmarks algorithm.  Previously it was attempted at the
   end after adding all cameras, often too late.  Now it is attempted the
   first time the ratio of reversed to non-reversed RMSE is within a threshold.
   Necker reversal is only attempted once.  It is either needed or not.

 * Added default version of dynamic_configuration which always returns
   an empty config block.

 * Added a core implementation of "filter_tracks" which applies filters based
   on track length or based on importance of the track in covering a match matrix.

 * Added a core implementation of "filter_features" which filters features
   based on key point scale.

 * Changed "match_features_homography" to apply feature filtering to both the
   source and destination frames.  This seems to be more robust when the number
   of features is very large.  Also adjusted the homography inlier scale with
   respect to the average scale of the features.

 * Added multi-threaded operation to close_loops_keyframe and
   close_loops_exhaustive algorithms.  Frame matching tasks are added to the
   thread pool.

 * Added a video_input algorithm for image lists that treats a sequence of
   images files like a video, using an image_io algorithm to load each frame.

 * Added a video_input algorithm for POS files that produces a metadata-only
   stream out of POS files associated with a list of images.  Each image file
   name is matched to a POS file with the same base name in a specified metadata
   directory.

 * Added a video_input algorithm that splits imagery and metadata between two
   other video_input sources.  For example this implementation can combine the
   images from an image_list video_input and metadata from a POS video_input.

 * Added a video_input filter algorithm that reads data from another
   video_input instance and reduces the frame range or adjusts frame timing.

 * Updated hierarchical_bundle_adjust and initialize_cameras_landmarks to
   accept an optional metadata_map and pass it along to nested algorithms.

 * Generalized the track_features_core algorithm to handle tracking on frames
   that may come out of order and frames that have already been tracked.  Also
   removed the caching of the next frame id in the algorithm and now retrieve it
   from the existing track set instead.  These changes are to support the
   MAP-Tk GUI which allows users to stop tracking, change the active frame,
   and start a new tracker.

 * Loop closure is now an optional component algorithm of the core feature
   tracker.  Leaving the loop closure algorithm unspecified will cause the
   tracker to skip loop closure.

 * Updated the core tracking algorithm to read and write features and
   descriptors to disk if a feature_descriptor_io algorithm is specified.

 * Changed the meaning of the final_reproj_thresh parameter of the core
   initialize_cameras_landmarks algorithm to be relative to the final median
   reprojection error rather than an absolute measure.  This adaptive
   threshold is more robust.

Arrows - OpenCV

 * Updated the OpenCV image container functions to handle conversions between
   vital::image and cv::Mat for all supported pixel types and memory layouts.

 * Updated the ocv::image_io algorithm to load images of various pixel types
   and to explicitly apply BGR to RGB conversions instead of hiding those
   color conversions elsewhere (see fixes below).

 * Added implementation for draw_detected_object_set.

Arrows - VXL

 * Updated the VXL image container functions to handle conversions between
   vital::image and vil_image_view_base_sptr for all supported pixel types and
   memory layouts.

 * Generalized the vxl::image_io algorithm to read and write images with
   different pixel formats (bool, uint8, uint16, float, etc.).  Added a
   "force_byte" option to always load or save as uint8 regardless of the
   underlying data type.  Generalized the range stretching options to apply
   to and from types other than uint8.  Range stretch now applies to save
   as well as load

Arrows - Darknet

 * Added image_object_detector implementation using Darknet
   implementation of you only look once (YOLO), state-of-the-art,
   real-time object detection system. Currently requires an external
   build of the Darknet project - https://gitlab.kitware.com/kwiver/darknet.git

Arrows - Burnout

 * Added burnout descriptors.

Vital

 * Generalized the vital::image class to store pixel types other than bytes.
   A new image_pixel_traits struct is used to hold the number of bytes per pixel
   and an enum describing how to interpret the pixel (signed, unsigned, float,
   etc.).  A new derived class image_of<T> allows convenience construction and
   interface with images where pixel type T is known at compile time.

 * Added an is_contiguous() member function on vital::image to check if the
   data is laid out in contiguous memory.

 * Moved the transform_image function to vital/util/transform_image.h, a new
   header, and generalized it to use any pixel type.  Switched to a template
   argument for the function parameter to allow passing in functors.

 * Added a second transform_image function to transforms one image into another
   image, not in-place like the previous function.  This version can transform
   one image into another with a different pixel type.

 * Added a cast_image function which uses the transform_image function to
   apply a static cast between image types.

 * Expanded unit tests to evaluate different pixel data types and test the
   is_contiguous member function.

 * Added a vital::image_type_mismatch_exception to throw in cases where
   the pixel data type does not match what is expected.

 * Updated the C bindings for vital::image to support pixel types.  Added
   get_pixel2 and get_pixel3 variants for the most common data types.
   Added a bindings for is_contiguous and equal_content.

 * Updated the Python bindings for vital::image to support pixel types.
   Added bindings for get_pixel2 and get_pixel3 variants, is_contiguous,
   equal_content, and others.  Updated the conversion to PIL to work with
   different pixel types.

 * Added callback registration to two abstract algorithms: bundle_adjust and
   initialize_cameras_landmarks.  Callbacks allow the algorithms to report
   progress updates.  They also allow the receiver to terminate the algorithm
   early.

 * Added deep copy support to detected object sets and contained
   classes. These class are detected_object_set, detected_object and
   attribute_set.

 * Added unified module loader to handle algorithms, processes,
   clusters, and ad-hoc modules. The plugin_explorer tool has been
   expanded to better handle the different plugin types and streamline
   its use as a reference source.

 * Added abstract algorithm for draw_detected_object_set. This
   provides an interface for drawing the outlines for detected
   objects.

 * Added abstract algorithm to support dynamic configuration
   values. An implementation of this interface would provide updated
   config values at run time. The use case for this algorithm is
   situations where an external real-time control (e.g. a GUI control)
   is used to vary an algorithm configuration value and the algorithm
   is to respond in real-time. A typical parameter that could be
   varied in this manner would be a threshold or a scaling value.

 * Added feature to plugin_explorer to allow filtering by
   implementation type and factory type when selecting by category.

 * Added method to do a set difference between two config blocks. This
   can be used to validate config blocks against a known
   standard. Also added functions to determine both difference sets.

 * Added track descriptor support classes for representation and
   computation of track based descriptors.

 * Added UID class to represent a unique identifier. These identifiers
   can be set to an arbitrary set of bytes that represent a unique ID
   within a smaller universe or use a factory to create a more
   globally unique ID. Added uuid factory to create universal unique
   IDs.

 * Added algorithm classes to support query formulation with concrete
   implementations.

 * Added classes to support track descriptor set input and output.

 * Added geographic point and polygon types.

 * Added a "filter_tracks" abstract algorithm to apply filters to feature tracks

 * Added a singleton thread pool class in vital/utils to distribute tasks over
   a fixed number of threads.

 * Added new methods "read_pos_file" and "write_pos_file" in the video_metadata
   library to read AFRL POS files directly into a video_metadata structure and
   write POS files from a video_metadata structure.

 * Added new video_metadata tags corresponding to fields that are required for
   POS files.

 * Added a new metadata_map container to hold a mapping between frame number
   and video_metadata vectors.  This container is for passing all the metadata
   through the algorithm APIs.

 * Updated the APIs for various abstract algorithms to accept an optional
   metadata_map.  This includes initialize_cameras_landmarks, bundle_adjust,
   and optimize_cameras.

 * Added an "insert" member function to the track data structure to insert
   track states at any frame position, as long as that frame is not already
   occupied.

 * Added an optional video_metadata member to the image_container class so that
   metadata for images can be easily carried along with the image data.

 * Added a utility function to construct a base filename from a metadata packet
   and frame number in a consistent way for use in naming cache files
   associated with video frames.

 * Improved Python bindings completeness, added additional Python tests, and
   extended documentation of Python bindings.

Sprokit

 * Added sprokit port operations that have timeout. Allows process to
   limit how long it will wait for data to be provided or
   accepted. This option is available on a port by port basis based on
   which method is used.

 * Added non-blocking option for processes. This option causes data
   supplied to input ports of a process to be dropped if the input
   edge buffers are full. This operates on a per-process basis so that
   all input edges have the same capacity, and when an edge is full,
   all inputs are dropped.

 * Modified embedded pipeline to handle applications where there are
   source and/or sink processes in the pipeline. Initially, the
   application had to handle sourcing and sinking the data through
   adapter processes. The change makes the required input/output
   adapter processes to be optional.

 * Removed process and cluster loaders. Updated process registry files
   to use the new process loader approach.

 * Added CMake option to specify the default edge capacity at compile
   time. The old default was for unlimited edge capacity which does
   not work well for large data sets. The edge capacity can also be
   set in the pipeline file, but this option provides a system wide
   default.

 * Added process to wrap draw_detected_object_set algorithm.

 * Added detected_object_set input and output processes and algorithms.

 * Added pipeline export class which writes a fully resolved pipeline
   to a file in the form where it can be used as input.

 * Replaced pipeline parser to support vital config file syntax in
   addition to the original sprokit pipeline syntax. Some minor
   semantic differences were introduced in the process.

 * Added processes to support track descriptor input and output.

Vital Bindings

 * Fixed bug in python ConfigBlock read-from-file.

 * Added more C/Python bindings for vital::track class

 * Added more C/Python bindings for vital::track_set class

 * Added full C/Python bindings for vital::landmark class

 * Added full C/Python bindings for vital::landmark_map class

 * Added full C/Python bindings for vital::similarity class

 * Added full C/Python bindings for vital::homography class

 * Added C/Python interface for bundle_adjust algorithm definition

 * Added C/Python interface for initialize_cameras_landmarks algorithm
   definition

 * Added C/Python interface for triangulate_landmarks algorithm definition

 * Added C/Python interface for geo_map algorithm definition

 * Added C/Python interface for estimate_similarity_transform algorithm
   definition

 * Added C/Python interface for estimate_canonical_transform algorithm
   definition

 * Added C/Python interface for vital::bounding_box class

 * Added C/Python interface for vital::detected_object class

 * Added C/Python interface for vital::detected_object_type class

 * Added C/Python interface for vital::detected_object_set class

 * Added python bindings for descriptor sets and detected object sets.

Fixes since v1.0.0
------------------

Arrows

 * Fixed plugin export symbols and include files to fix Windows build
   issues. Generate separate include files for plugin stubs.

Arrows - Core

 * The match_feature_homography class had a bug in which the feature matches
   used in homography estimation indexed into the source features rather than
   the filtered features.  As a result, when a filter was used, the feature
   locations where incorrect causing the algorithm to fail.  The code has now
   been corrected to properly use the filtered feature list.

Arrows - OpenCV

 * Fixed a potential crash when wrapping a cv::Mat into a mat_image_memory
   object.  If the cv::Mat did not own its data and had no reference counter
   the mat_image_memory would still try to increment it (OpenCV 2.4.X only).

 * Reverted a previous workaround to the OpenCV BGR vs. RGB issue that was
   reversing the color channels during every cv::Mat to vital::image conversion
   This was error prone and missed some corner cases.  The conversion will
   be made explicitly elsewhere when needed.

Vital

 * The C binding vital_image_new_from_data contained a weird hack that
   convert BGR to RGB and copied data instead of simply calling the
   corresponding C++ code.  This has been removed.  Another solution
   should be found if this causes problems elsewhere.

 * Moved list copy in detected_object_set to eliminate collisions in
   select methods.

 * Updated some outdated comments in feature_set and descriptor_set.
